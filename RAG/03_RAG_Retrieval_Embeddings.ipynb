{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "#### Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../openai_api_key.txt\") as f:\n",
    "    api_key = f.read()\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The scar had not pained Harry for nineteen years. All was well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.006067691294778975, -0.006654051049083575, 0.03343223365953213, -0.02039625470103048, -0.008338620781671906]\n",
      "1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding the text\n",
    "\n",
    "embedded_text = embeddings.embed_query(text)\n",
    "print(embedded_text[:5]), print(len(embedded_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If we have n lines in langchain document format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The scar had not pained Harry for nineteen years. All was well.', metadata={'source': 'Harry Potter'}),\n",
       " Document(page_content='It is our choices, Harry, that show what we truly are, far more than our abilities', metadata={'source': 'Harry Potter'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "doc_lines = [\n",
    "    Document(page_content=text, metadata = {\"source\":\"Harry Potter\"}),\n",
    "    Document(page_content=\"It is our choices, Harry, that show what we truly are, far more than our abilities\", metadata = {\"source\":\"Harry Potter\"})\n",
    "]\n",
    "doc_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The scar had not pained Harry for nineteen years. All was well.',\n",
       " 'It is our choices, Harry, that show what we truly are, far more than our abilities']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets extract the page content\n",
    "line_List = [doc.page_content for doc in doc_lines]\n",
    "line_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embedded_docs = [embeddings.embed_query(text) for text in line_List]\n",
    "\n",
    "np.array(embedded_docs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets explore some open source embedding models\n",
    "\n",
    "#### BGE Embeddings( BAAI(Beijing Academy of Artificial Intelligence) General Embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (4.38.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\onedrive\\desktop\\llms_intro\\langchain_new_env\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\HP\\OneDrive\\Desktop\\LLMs_Intro\\langchain_new_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Desktop\\LLMs_Intro\\langchain_new_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\HP\\OneDrive\\Desktop\\LLMs_Intro\\langchain_new_env\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--BAAI--bge-base-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {\"device\":'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings':True}\n",
    "\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = model_kwargs,\n",
    "    encode_kwargs = encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embedded_docs = [hf.embed_query(text) for text in line_List]\n",
    "\n",
    "np.array(embedded_docs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAKE EMBEDDINGS\n",
    "\n",
    "#### For testing purposes, if you have some hardware restrictions, you can use Fake Embeddings from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "\n",
    "fake_embeddings = FakeEmbeddings(size = 300) # embedding size\n",
    "\n",
    "fake_embedding_record = fake_embeddings.embed_query(\"This is a random text\")\n",
    "fake_embedding_records = fake_embeddings.embed_documents([\"This is a random text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single record\n",
    "np.array(fake_embedding_record).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple records\n",
    "np.array(fake_embedding_records).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
